{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Is the NBA Becoming a More Global Product: An Analysis of NBA Player Distribution and Trends**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "This project explores the globalisation of the NBA by analysing advanced statistics, player distribution, and trends over time. Using advanced metrics, each player is assigned a composite score to quantify their performance for a given season. By filtering for the top 10 NBA players over the past three seasons based on this composite score, this study aims to evaluate whether globalisation is permeating the leagueâ€™s elite ranks. Furthermore, this project examines player distributions by nationality over the same period to assess the broader impact of globalisation on the league.\n",
    "\n",
    "**Key Questions:**\n",
    "1. Who are the top 10 players in the NBA based on performance over the past three seasons?\n",
    "2. How has the distribution of NBA players by nationality evolved over the same period?\n",
    "\n",
    "This analysis leverages data from two primary sources:\n",
    "- **[Basketball-Reference.com](https://www.basketball-reference.com):** A widely respected resource for historical and current NBA data, providing comprehensive player statistics and advanced metrics.\n",
    "- **[NBA API](https://developer.nba.com/):** An official source of real-time league data, offering up-to-date player metrics and team statistics for robust and accurate analysis.\n",
    "\n",
    "By examining these questions and trends, this study seeks to uncover whether the influx of international players is reshaping the league and determine if these players are competing at the highest levels of basketball excellence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import os \n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO, BytesIO\n",
    "from unidecode import unidecode\n",
    "import unicodedata\n",
    "from nba_api.stats.endpoints import leaguedashplayerstats, commonplayerinfo\n",
    "from nba_api.stats.library.parameters import SeasonTypeAllStar\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "from psycopg2 import OperationalError\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read Environment Variables from Config File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables manually\n",
    "env_file = \"config.env\"\n",
    "if os.path.exists(env_file):\n",
    "    with open(env_file) as f:\n",
    "        for line in f:\n",
    "            key, value = line.strip().split(\"=\")\n",
    "            os.environ[key] = value  # Store in environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basketball-Reference Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliterate_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Ensures names are alphabetic and free of special characters or accents.\n",
    "    \"\"\"\n",
    "    if isinstance(name, str):\n",
    "        name = unicodedata.normalize(\"NFKD\", name)\n",
    "        name = unidecode(name)\n",
    "        name = ''.join(c for c in name if c.isalpha() or c.isspace()).strip()\n",
    "    return name\n",
    "\n",
    "\n",
    "def ensure_folder_exists(folder_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Ensures the specified folder exists.\n",
    "    \"\"\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def scrape_save_stats(season: str, folder_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Scrapes advanced stats from Basketball-Reference for a given season and saves HTML files.\n",
    "    Returns the file path of the saved HTML.\n",
    "    \"\"\"\n",
    "    ensure_folder_exists(folder_path)\n",
    "    file_name = f\"bball_ref_20{season.split('-')[1]}.html\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Scraping data for the {season} season...\")\n",
    "        url = f\"https://www.basketball-reference.com/leagues/NBA_20{season.split('-')[1]}_advanced.html\"\n",
    "        response = requests.get(url)\n",
    "        response.encoding = 'utf-8'\n",
    "        response.raise_for_status()\n",
    "\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"File saved: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Data already saved for {season} season.\")\n",
    "\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def parse_and_clean(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parses an HTML file, extracts and cleans the advanced stats table, and returns a DataFrame.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html5lib\")\n",
    "    table = soup.find(\"table\", {\"id\": \"advanced\"})\n",
    "    if not table:\n",
    "        raise ValueError(f\"No table found in file: {file_path}\")\n",
    "\n",
    "    df = pd.read_html(StringIO(str(table)))[0]\n",
    "    df = df[df[\"Player\"] != \"Player\"]  # Remove duplicate headers\n",
    "    df = df[[\"Player\", \"Team\", \"G\", \"PER\", \"TS%\", \"USG%\", \"WS/48\", \"BPM\", \"VORP\"]]\n",
    "    df.columns = [\"player\", \"team\", \"games_played\", \"per\", \"ts\", \"usg\", \"ws_48\", \"bpm\", \"vorp\"]\n",
    "    df[\"player\"] = df[\"player\"].str.strip().apply(transliterate_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def collect_scraped_data(seasons: list[str], folder_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Collects and compiles scraped advanced stats data for the specified seasons.\n",
    "    \"\"\"\n",
    "    all_stats = []\n",
    "    for season in seasons:\n",
    "        try:\n",
    "            file_path = scrape_save_stats(season, folder_path)\n",
    "            season_data = parse_and_clean(file_path)\n",
    "            season_data[\"season\"] = season\n",
    "            all_stats.append(season_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing data for {season}: {e}\")\n",
    "\n",
    "    if not all_stats:\n",
    "        raise ValueError(\"No valid data collected for any season.\")\n",
    "\n",
    "    return pd.concat(all_stats, ignore_index=True)\n",
    "\n",
    "\n",
    "last_3_seasons = [\"2023-24\", \"2022-23\", \"2021-22\"]\n",
    "folder_path = \"./data/bball_ref\"\n",
    "\n",
    "bball_ref_df = collect_scraped_data(last_3_seasons, folder_path)\n",
    "\n",
    "print(\"Data collection and cleaning completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bball_ref_df` includes the following columns:  \n",
    "\n",
    "| **Column**                       | **Description**                                                                 |\n",
    "|----------------------------------|---------------------------------------------------------------------------------|\n",
    "| Player                        | Full name of player                                                                      |\n",
    "| Team                        | 3-letter team label (e.g. LAL)                                                 |\n",
    "| Season                      | NBA season (e.g. \"2023-24\")                                                    |\n",
    "| Games Played                | Number of games played in the season                                           |\n",
    "| Player Efficiency Rating (PER) | A per-minute rating summarising accomplishments, adjusted for pace; avg = 15   |\n",
    "| True Shooting Percentage (TS%) | Accounts for field goals, three-point shots, and free throws                   |\n",
    "| Usage Percentage (USG%)     | Percentage of team plays used, including FG attempts, FT attempts, and turnovers |\n",
    "| Win Shares per 48 Minutes (WS/48)| Contribution to team wins, normalised to 48 minutes; league avg = 0.100       |\n",
    "| Box Plus/Minus (BPM)        | Impact on team's performance per 100 possessions compared to a league-average player |\n",
    "| Value Over Replacement (VORP) | Contribution above replacement-level player, scaled per season                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NBA API Data Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_folder_exists(folder_path: str) -> None:\n",
    "    \"\"\"Ensures the specified folder exists.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        print(f\"Folder checked/created: {folder_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error ensuring folder exists: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_nationality_cache(nationality_filepath: str) -> dict:\n",
    "    \"\"\"Loads the nationality cache from a CSV file if it exists.\"\"\"\n",
    "    if os.path.exists(nationality_filepath):\n",
    "        try:\n",
    "            nationality_df = pd.read_csv(nationality_filepath)\n",
    "            print(f\"Loaded player nationalities from cache: {len(nationality_df)} players.\")\n",
    "            return nationality_df.set_index(\"player_id\")[\"nationality\"].to_dict()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading nationality cache: {e}\")\n",
    "            return {}\n",
    "    print(\"No nationality cache found; starting fresh.\")\n",
    "    return {}\n",
    "\n",
    "def save_nationality_cache(nationality_filepath: str, new_nationalities: list[dict]) -> None:\n",
    "    \"\"\"Saves the updated nationality cache to a CSV file.\"\"\"\n",
    "    if new_nationalities:\n",
    "        try:\n",
    "            new_nationalities_df = pd.DataFrame(new_nationalities)\n",
    "            if os.path.exists(nationality_filepath):\n",
    "                cached_nationalities = pd.read_csv(nationality_filepath)\n",
    "                new_nationalities_df = pd.concat(\n",
    "                    [cached_nationalities, new_nationalities_df], ignore_index=True\n",
    "                ).drop_duplicates()\n",
    "            new_nationalities_df.to_csv(nationality_filepath, index=False)\n",
    "            print(f\"Updated player nationalities saved to {nationality_filepath}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving nationality cache: {e}\")\n",
    "            raise\n",
    "\n",
    "def fetch_season_stats(season: str, season_filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"Fetches and saves advanced stats for a given season.\"\"\"\n",
    "    if os.path.exists(season_filepath):\n",
    "        print(f\"Loading data for season {season} from cache.\")\n",
    "        return pd.read_csv(season_filepath)\n",
    "\n",
    "    print(f\"Fetching data for season {season}...\")\n",
    "    try:\n",
    "        stats = leaguedashplayerstats.LeagueDashPlayerStats(\n",
    "            season=season,\n",
    "            season_type_all_star=SeasonTypeAllStar.regular,\n",
    "            measure_type_detailed_defense=\"Advanced\",\n",
    "            per_mode_detailed=\"PerGame\"\n",
    "        ).get_data_frames()[0]\n",
    "\n",
    "        # Keep only relevant columns\n",
    "        stats = stats[[\"PLAYER_ID\", \"PLAYER_NAME\", \"TEAM_ABBREVIATION\", \"GP\", \"MIN\", \"OFF_RATING\", \"DEF_RATING\"]]\n",
    "        stats.columns = [\"player_id\", \"player\", \"team\", \"games_played\", \"min\", \"off_rating\", \"def_rating\"]\n",
    "        stats[\"season\"] = season\n",
    "\n",
    "        # Save to CSV\n",
    "        stats.to_csv(season_filepath, index=False)\n",
    "        print(f\"Season {season} data saved to {season_filepath}.\")\n",
    "        return stats\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for season {season}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame on failure\n",
    "\n",
    "def fetch_player_nationalities(unique_player_ids: set, player_nationality_cache: dict) -> list[dict]:\n",
    "    \"\"\"Fetches nationalities for unique player IDs and updates the cache.\"\"\"\n",
    "    new_nationalities = []\n",
    "\n",
    "    for player_id in unique_player_ids:\n",
    "        if player_id not in player_nationality_cache:\n",
    "            try:\n",
    "                player_info = commonplayerinfo.CommonPlayerInfo(player_id=player_id).get_data_frames()[0]\n",
    "                nationality = player_info.loc[0, \"COUNTRY\"]\n",
    "                player_nationality_cache[player_id] = nationality\n",
    "                new_nationalities.append({\"player_id\": player_id, \"nationality\": nationality})\n",
    "                print(f\"Fetched nationality for player ID {player_id}: {nationality}\")\n",
    "                time.sleep(1)  # Avoid hitting rate limits\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching nationality for player ID {player_id}: {e}\")\n",
    "                player_nationality_cache[player_id] = \"unknown\"\n",
    "                new_nationalities.append({\"player_id\": player_id, \"nationality\": \"unknown\"})\n",
    "\n",
    "    return new_nationalities\n",
    "\n",
    "def fetch_advanced_stats_with_nationality(seasons: list[str], folder_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches advanced stats and player nationalities, saves data to avoid redundant API calls.\n",
    "    \"\"\"\n",
    "    ensure_folder_exists(folder_path)\n",
    "    nationality_filepath = os.path.join(folder_path, \"player_nationality.csv\")\n",
    "    player_nationality_cache = load_nationality_cache(nationality_filepath)\n",
    "\n",
    "    all_stats = []\n",
    "    unique_player_ids = set()\n",
    "\n",
    "    for season in seasons:\n",
    "        season_filepath = os.path.join(folder_path, f\"nba_stats_{season.replace('-', '_')}.csv\")\n",
    "        season_stats = fetch_season_stats(season, season_filepath)\n",
    "        if not season_stats.empty:\n",
    "            all_stats.append(season_stats)\n",
    "            unique_player_ids.update(season_stats[\"player_id\"].unique())\n",
    "        time.sleep(2)  # Avoid hitting rate limits\n",
    "\n",
    "    new_nationalities = fetch_player_nationalities(unique_player_ids, player_nationality_cache)\n",
    "    save_nationality_cache(nationality_filepath, new_nationalities)\n",
    "\n",
    "    if not all_stats:\n",
    "        print(\"No data was fetched for the specified seasons.\")\n",
    "        raise ValueError(\"No data was fetched for the specified seasons.\")\n",
    "\n",
    "    combined_stats = pd.concat(all_stats, ignore_index=True)\n",
    "    combined_stats[\"nationality\"] = combined_stats[\"player_id\"].map(player_nationality_cache)\n",
    "\n",
    "    return combined_stats\n",
    "\n",
    "# Execution logic for the notebook\n",
    "last_3_seasons = [\"2023-24\", \"2022-23\", \"2021-22\"]\n",
    "folder_path = \"./data/nba_api\"\n",
    "\n",
    "nba_api_df = fetch_advanced_stats_with_nationality(last_3_seasons, folder_path)\n",
    "nba_api_df[\"player\"] = nba_api_df[\"player\"].str.strip().apply(transliterate_name)\n",
    "\n",
    "print(\"Data fetching complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nba_api_df` DataFrame includes the following columns:\n",
    "\n",
    "| **Column**                       | **Description**                                                                 |\n",
    "|----------------------------------|---------------------------------------------------------------------------------|\n",
    "| Player ID                        | Unique ID assigned to player                                                 |\n",
    "| Player                        | Full name of player                                                                      |\n",
    "| Team                        | 3-letter team label (e.g. LAL)                                                 |\n",
    "| Games Played                | Number of games played in the season                                           |\n",
    "| Min                | Minutes played per game                                           |\n",
    "| Offensive Rating                | Estimate of the number of points a player produces per 100 possessions                                           |\n",
    "| Defensive Rating                | Estimate of the number of points a player allows per 100 possessions                                           |\n",
    "| Season                      | NBA season (e.g. \"2023-24\")                                                    |\n",
    "| Nationality                      | Nationality of player                                                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary of Data Collected**\n",
    "\n",
    "**Sample Data for Basketball-Reference Data**\n",
    "\n",
    "| Player            | Team | Games Played | PER  | TS    | USG  | WS/48  | BPM  | VORP | Season  |\n",
    "|------------------|------|--------------|------|------|------|--------|------|------|---------|\n",
    "| DeMar DeRozan   | CHI  | 79.0         | 19.7 | 0.584 | 25.8 | 0.147  | 1.8  | 2.8  | 2023-24 |\n",
    "| Domantas Sabonis| SAC  | 82.0         | 23.2 | 0.637 | 22.2 | 0.206  | 6.5  | 6.2  | 2023-24 |\n",
    "| Coby White      | CHI  | 79.0         | 14.5 | 0.570 | 22.7 | 0.078  | -0.7 | 0.9  | 2023-24 |\n",
    "| Mikal Bridges   | BRK  | 82.0         | 14.9 | 0.560 | 24.3 | 0.070  | -0.4 | 1.2  | 2023-24 |\n",
    "| Paolo Banchero  | ORL  | 80.0         | 17.3 | 0.546 | 29.7 | 0.090  | 1.3  | 2.3  | 2023-24 |\n",
    "\n",
    "**Sample Data for NBA API Data**\n",
    "\n",
    "| player_id | Player       | Team | Games Played | Min  | Off Rating | Def Rating | Season  | Nationality |\n",
    "|-----------|-------------|------|--------------|------|------------|------------|---------|-------------|\n",
    "| 1630639   | AJ Lawson   | DAL  | 42           | 7.4  | 106.6      | 105.3      | 2023-24 | Canada      |\n",
    "| 1631260   | AJ Green    | MIL  | 56           | 11.0 | 114.0      | 110.5      | 2023-24 | USA         |\n",
    "| 1631100   | AJ Griffin  | ATL  | 20           | 8.5  | 106.0      | 120.1      | 2023-24 | USA         |\n",
    "| 203932    | Aaron Gordon| DEN  | 73           | 31.5 | 119.8      | 111.1      | 2023-24 | USA         |\n",
    "| 1628988   | Aaron Holiday| HOU  | 78           | 16.3 | 110.5      | 107.6      | 2023-24 | USA         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Cleaning**\n",
    "\n",
    "The data cleaning process involves the following steps:\n",
    "\n",
    "- **Handling Missing Values:**  \n",
    "  Records with missing values are either dropped or imputed using weighted averages to ensure data completeness and reliability.\n",
    "\n",
    "- **Data Alignment:**  \n",
    "  Aligning Basketball-Reference data with NBA API data is critical for seamless merging downstream. Key differences addressed include:  \n",
    "  - **Players on Multiple Teams in One Season:**  \n",
    "    - NBA API data provides aggregated records for players who played for multiple teams in a season.  \n",
    "    - Basketball-Reference data includes both aggregated records and individual team records for such players.\n",
    "    - NBA API data records the team a player last played for during the season in the aggregated record. In contrast, Basketball-Reference uses custom labels, such as `\"3TM\"`, to indicate that a player participated for three different teams in a single season.\n",
    "  - **Team Labels:**  \n",
    "    - Team labels differ between the datasets for certain teams (e.g., Brooklyn Nets recorded as `BRK` in Basketball-Reference and `BKN` in the NBA API).  \n",
    "\n",
    "These adjustments ensure consistency across datasets and facilitate accurate analysis in subsequent steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Missing Values: Basketball-Reference Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_ref_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bball_ref_df` dataframe contains 2,229 rows and 10 columns. It includes missing values in the following columns: `team`, `games_played`, `per`, `ts`, `ws_48`, `bpm`, and `vorp`. The data types of each column appear to be appropriate for analysis.\n",
    "\n",
    "To handle missing values, I plan to impute them using a weighted average based on the total number of games played. The imputation process will follow these steps:\n",
    "\n",
    "1. **Single Record Players:**  \n",
    "   Players with only one record across all seasons (i.e., those who played for a single team in only one season) will be removed from the dataset.\n",
    "\n",
    "2. **Players on Multiple Teams in a Single Season:**  \n",
    "   For players who played for multiple teams in one season, missing values will be imputed using a weighted average, calculated based on the number of games played for each team during that season.\n",
    "\n",
    "3. **Players with Mixed Records:**  \n",
    "   For players with missing data in single-team seasons who also played for multiple teams in other season(s), the missing values will be imputed using a weighted average across all their seasons. Any imputed values from step 2 (for multi-team seasons) will be incorporated into this calculation when necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_multi_team_players(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Finds and returns rows for players who played for multiple teams in one season.\n",
    "    \"\"\"\n",
    "    multi_team_check = df.groupby(['player', 'season'], as_index=False)['team'].nunique().query('team > 1')\n",
    "    multi_team_players = df[\n",
    "        df.set_index(['player', 'season']).index.isin(multi_team_check.set_index(['player', 'season']).index)\n",
    "    ]\n",
    "    return multi_team_players\n",
    "\n",
    "\n",
    "def impute_weighted_avg(df: pd.DataFrame, numeric_cols: list, group_by: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Imputes missing numeric values using a weighted average based on games played.\n",
    "    \"\"\"\n",
    "    if 'games_played' not in df.columns:\n",
    "        raise KeyError(\"'games_played' column is missing from the DataFrame.\")\n",
    "        \n",
    "    grouped = df.groupby(group_by)\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns and df[col].isnull().any():\n",
    "            print(f\"Imputing column: {col}\")\n",
    "            df.loc[:, col] = grouped.apply(\n",
    "                lambda group: group[col].fillna(\n",
    "                    (group['games_played'] * group[col]).sum() / group['games_played'].sum()\n",
    "                    if group['games_played'].sum() > 0 else group[col].mean()\n",
    "                ), include_groups=False\n",
    "            ).reset_index(level=group_by, drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def update_with_imputed_records(original_df: pd.DataFrame, imputed_df: pd.DataFrame, numeric_cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Updates the original DataFrame with imputed data for numeric columns.\n",
    "    \"\"\"\n",
    "    original_df = original_df.merge(\n",
    "        imputed_df[['player', 'season', 'team'] + numeric_cols],\n",
    "        on=['player', 'season', 'team'],\n",
    "        how='left',\n",
    "        suffixes=('', '_imputed')\n",
    "    )\n",
    "    for col in numeric_cols:\n",
    "        imputed_col = f'{col}_imputed'\n",
    "        if imputed_col in original_df.columns:\n",
    "            original_df[col] = original_df[imputed_col].where(original_df[imputed_col].notnull(), original_df[col])\n",
    "            original_df.drop(columns=[imputed_col], inplace=True)\n",
    "\n",
    "\n",
    "    return original_df\n",
    "\n",
    "\n",
    "def drop_and_impute(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drops certain records, imputes missing values for multi-team players,\n",
    "    imputes across seasons, and adds aggregated records back.\n",
    "    \"\"\"\n",
    "    # Step 1: Remove Single-Season Players and Records with Missing Games Played\n",
    "    single_record_players = df.groupby(['player'], as_index=False)['season'].nunique().query('season == 1')\n",
    "    print(f\"Total number of players that only played one season: {single_record_players.shape[0]} players\")\n",
    "    clean_df = df[~df['player'].isin(single_record_players['player'])]\n",
    "    print(f\"Total rows after removing single-season players: {clean_df.shape[0]} rows\")\n",
    "\n",
    "    clean_df = clean_df[clean_df['games_played'].notnull()]\n",
    "    print(f\"Total rows after removing records with missing games played: {clean_df.shape[0]} rows\")\n",
    "\n",
    "    # Separate aggregate rows from non-aggregate rows\n",
    "    agg_records = clean_df[clean_df['team'].str.contains(r'^\\dTM$', na=False)]\n",
    "    non_agg_records = clean_df[~clean_df['team'].str.contains(r'^\\dTM$', na=False)]\n",
    "    print(f\"Aggregated records: {agg_records.shape[0]} rows\")\n",
    "    print(f\"Non-aggregated records: {non_agg_records.shape[0]} rows\")\n",
    "\n",
    "    # Step 2: Perform Imputations\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "    # Impute for Multi-Team Players\n",
    "    multi_team_players = find_multi_team_players(non_agg_records)\n",
    "    print(\"Columns in multi_team_players:\", multi_team_players.columns)\n",
    "    imputed_multi_df = impute_weighted_avg(multi_team_players, numeric_cols, group_by=['player', 'season'])\n",
    "\n",
    "    # Update Non-Aggregated Records with Imputed Multi-Team Player Data\n",
    "    non_agg_records = update_with_imputed_records(non_agg_records, imputed_multi_df, numeric_cols)\n",
    "\n",
    "    # Impute Across Seasons for All Players\n",
    "    final_imputed_df = impute_weighted_avg(non_agg_records, numeric_cols, group_by=['player'])\n",
    "\n",
    "    # Update Non-Aggregated Records with Season-Level Imputations\n",
    "    non_agg_records = update_with_imputed_records(non_agg_records, final_imputed_df, numeric_cols)\n",
    "\n",
    "    # Step 3: Add Aggregated Records Back\n",
    "    final_df = pd.concat([non_agg_records, agg_records], ignore_index=True)\n",
    "    print(\"Missing values have been dropped or imputed.\")\n",
    "\n",
    "    # Debug: Check for Remaining Missing Values\n",
    "    print(\"Final DataFrame missing values:\\n\", final_df.isnull().sum())\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_imputed_df = drop_and_impute(bball_ref_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Missing Values: NBA API Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_api_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1716 rows and 8 columns. There are no missing values and the datatype of each column is appropriate. Records for players who only played for one season are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_dropped_df = drop_and_impute(nba_api_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Alignment: Aggregate Record Team Labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One key difference between the two datasets is how records for players who played for multiple teams in one season are recorded. Basketball-reference provides both aggregated data and individual stats for each team. The NBA API dataset only provides aggregated record. Furthermore, while they both provide aggregated records, Basketball-Reference uses a digit followed by TM to describe the total number of teams the player was on in that season. The NBA API simply inputs the last team they played for in that season. We will align the Basketball-Reference dataset to the NBA API dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_multi_team_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handles players who played for multiple teams by assigning the team label\n",
    "    based on the last occurrence in the records for a single season.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with columns including 'player', 'season',\n",
    "                           'team', and 'games_played'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with multi-team players assigned the label\n",
    "                      of the team appearing last in the records for the season.\n",
    "    \"\"\"\n",
    "    # Separate multi-team players\n",
    "    aggregate_records_mask = df['team'].str.contains(r'^\\dTM$', na=False)\n",
    "    aggregate_records = df[aggregate_records_mask].copy()\n",
    "\n",
    "    # Identify the team for multi-team players based on the last occurrence\n",
    "    last_team_mapping = (\n",
    "        df[~aggregate_records_mask]\n",
    "        .groupby(['player', 'season'], group_keys=False, as_index=False)\n",
    "        .tail(1)[['player', 'season', 'team']]  # Use tail(1) to get the last row per group\n",
    "        .rename(columns={'team': 'last_team'})\n",
    "    )\n",
    "\n",
    "    # Create mapping\n",
    "    mapping = last_team_mapping.set_index(['player', 'season'])['last_team'].to_dict()\n",
    "\n",
    "    # Map and replace team labels\n",
    "    aggregate_records['team'] = aggregate_records.set_index(['player', 'season']).index.map(mapping)\n",
    "\n",
    "    # Identify multi-team players with multiple teams in a single season\n",
    "    multi_team = (\n",
    "        df[~aggregate_records_mask]\n",
    "        .groupby(['player', 'season'])['team']\n",
    "        .nunique()\n",
    "        .reset_index()\n",
    "        .query('team > 1')[['player', 'season']]\n",
    "    )\n",
    "\n",
    "    # Filter out rows for multi-team players directly using an index-based approach\n",
    "    df = df[~aggregate_records_mask]\n",
    "    df = df[~df.set_index(['player', 'season']).index.isin(multi_team.set_index(['player', 'season']).index)\n",
    "    ]\n",
    "\n",
    "    # Combine cleaned data\n",
    "    df = pd.concat([df, aggregate_records], ignore_index=True).sort_values(by=['player', 'season'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Clean the data\n",
    "bball_ref_cleaned = clean_multi_team_data(bball_imputed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Alignment: NBA Team Labels**\n",
    "Basketball-reference has different team labels to the NBA API. In order to merge the two dataframes, they need to be standardised. Given the NBA API team labels are inherently easier to interpret, I will match the Basketball-Reference team labels to the NBA API's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique team labels\n",
    "print(\"Basketball-Reference Team Labels:\")\n",
    "print(f\"{np.sort(bball_ref_cleaned['team'].unique())}\\n\")\n",
    "print(\"NBA API Team Labels:\")\n",
    "print(np.sort(nba_dropped_df['team'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The teams with differing labels include: brooklyn, charlotte, and phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for known differences\n",
    "team_mapping = {'BRK': 'BKN', 'CHO': 'CHA', 'PHO': 'PHX'}\n",
    "\n",
    "# Align Basketball-Reference labels to NBA API labels\n",
    "bball_ref_cleaned['team'] = bball_ref_cleaned['team'].map(team_mapping).fillna(bball_ref_cleaned['team'])\n",
    "\n",
    "# Find differences in team labels\n",
    "print(set(bball_ref_cleaned['team']) - set(nba_dropped_df['team']))\n",
    "print(f\"Shape of basketball-reference df: {bball_ref_cleaned.shape}\")\n",
    "print(f\"Shape of NBA API df: {nba_dropped_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Alignment: Player Name Suffix**\n",
    "The two data sources differ in naming conventions with respect to player suffixes. As such, if a player has a suffix in one DataFrame but not in the other, the suffix will be included for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix(no_suffix_df: pd.DataFrame, suffix_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Finds player suffixes from one dataframe and adds them to matching names in the other.\n",
    "    \"\"\"\n",
    "    suffix_dict = {}\n",
    "    for name in suffix_df['player'].unique():\n",
    "        if len(name.split(' ')) == 3:\n",
    "            first_name, last_name, suffix = name.split(' ')\n",
    "            suffix_dict[f\"{first_name} {last_name}\"] = suffix\n",
    "    \n",
    "    # Add suffix to matching players in no_suffix_df\n",
    "    no_suffix_df['player'] = no_suffix_df['player'].apply(\n",
    "        lambda name: f\"{name} {suffix_dict[name]}\" if name in suffix_dict else name\n",
    "    )\n",
    "\n",
    "    return no_suffix_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_ref_cleaned = add_suffix(bball_ref_cleaned, nba_dropped_df)\n",
    "nba_cleaned = add_suffix(nba_dropped_df, bball_ref_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NBA Player Image Processing Pipeline**\n",
    "\n",
    "To generate more elegant visualisations in Power BI downstream, the code below generates **NBA player headshot URLs**, merges **nationality data with flag images**, and processes **player images into circular PNGs**. It takes `nba_cleaned` as input, assigns **headshot and flag URLs**, downloads images, applies **circular cropping**, and saves the final dataset as `player_headshots.csv`, with images stored in `visualisation/circular_headshots/`. ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nba_images(nba_df, flag_csv_path, output_csv_path, image_output_dir):\n",
    "    \"\"\"\n",
    "    Processes NBA player data by generating headshot URLs, merging with flag data, and processing images into circular format.\n",
    "    \n",
    "    Parameters:\n",
    "    nba_df (pd.DataFrame): Input DataFrame with 'player_id', 'player', and 'nationality' columns.\n",
    "    flag_csv_path (str): Path to CSV file containing country and flag URLs.\n",
    "    output_csv_path (str): Path where final processed CSV will be saved.\n",
    "    image_output_dir (str): Directory where processed circular headshots will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(image_output_dir, exist_ok=True)\n",
    "\n",
    "    # Create player headshot URLs\n",
    "    image_df = nba_df[['player_id', 'player', 'nationality']].drop_duplicates()\n",
    "    image_df['player_id'] = image_df['player_id'].astype(int)\n",
    "    image_df['player_url'] = image_df['player_id'].apply(\n",
    "        lambda id: f\"https://ak-static.cms.nba.com/wp-content/uploads/headshots/nba/latest/260x190/{id}.png\"\n",
    "    )\n",
    "\n",
    "    # Load flag CSV file and merge with image data\n",
    "    country_flags = pd.read_csv(flag_csv_path)\n",
    "    country_flags.rename(columns={\"URL\": \"flag_url\"}, inplace=True)\n",
    "\n",
    "    merge_on_country = pd.merge(image_df, country_flags, left_on=\"nationality\", right_on=\"Country\", how=\"left\")\n",
    "    merge_on_code = pd.merge(image_df, country_flags, left_on=\"nationality\", right_on=\"Code\", how=\"left\")\n",
    "    merge_on_country[\"flag_url\"] = merge_on_country[\"flag_url\"].fillna(merge_on_code[\"flag_url\"])\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    player_headshot_flag_df = merge_on_country[[\"player\", \"player_url\", \"flag_url\"]].drop_duplicates()\n",
    "\n",
    "    # Function to process images into circular format\n",
    "    def make_circular_image(image_url, save_path):\n",
    "        try:\n",
    "            # Download image\n",
    "            response = requests.get(image_url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to download: {image_url}\")\n",
    "                return None\n",
    "\n",
    "            img = Image.open(BytesIO(response.content)).convert(\"RGBA\")\n",
    "\n",
    "            # Ensure image is square by cropping the center\n",
    "            width, height = img.size\n",
    "            size = min(width, height)\n",
    "\n",
    "            left = (width - size) // 2\n",
    "            top = (height - size) // 2\n",
    "            right = left + size\n",
    "            bottom = top + size\n",
    "            img = img.crop((left, top, right, bottom))\n",
    "\n",
    "            # Create a circular mask\n",
    "            mask = Image.new(\"L\", (size, size), 0)\n",
    "            draw = ImageDraw.Draw(mask)\n",
    "            draw.ellipse((0, 0, size, size), fill=255)\n",
    "\n",
    "            # Apply circular mask with transparency\n",
    "            circular_img = Image.new(\"RGBA\", (size, size), (0, 0, 0, 0))\n",
    "            circular_img.paste(img, (0, 0), mask)\n",
    "\n",
    "            # Save the processed image\n",
    "            circular_img.save(save_path, format=\"PNG\")\n",
    "            return save_path\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_url}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Process each player's image into circular format\n",
    "    new_image_urls = []\n",
    "    for index, row in player_headshot_flag_df.iterrows():\n",
    "        player_name = row['player'].replace(\" \", \"_\").lower()\n",
    "        image_url = row['player_url']\n",
    "\n",
    "        save_path = os.path.join(image_output_dir, f\"{player_name}.png\").replace(\"\\\\\", \"/\")\n",
    "        processed_path = make_circular_image(image_url, save_path)\n",
    "\n",
    "        new_image_urls.append(processed_path if processed_path else image_url)\n",
    "\n",
    "    # Add new image column to DataFrame\n",
    "    player_headshot_flag_df[\"circular_player_url\"] = new_image_urls\n",
    "\n",
    "    # Save the final processed DataFrame to CSV\n",
    "    player_headshot_flag_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Processed images saved in: {image_output_dir}\")\n",
    "    print(f\"Updated CSV saved as: {output_csv_path}\")\n",
    "\n",
    "\n",
    "# Run only if player_headshots.csv file is missing or directory storing circular headshot files is missing\n",
    "if not (os.path.exists(\"./data/player_headshots.csv\") and os.path.isdir(\"./visualisation/circular_headshots\")):\n",
    "    process_nba_images(nba_cleaned, \"./data/flags_iso.csv\", \"./data/player_headshots.csv\", \"./visualisation/circular_headshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **circular images** of NBA player headshots were uploaded on the [**Github repository**](https://github.com/jung-hyung-lee/nba-global-trends/tree/main/visualisation/circular_headshots). The image URL for each player's image was then updated inside the `player_headshots.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CSV filepath\n",
    "csv_filepath = \"./data/player_headshots.csv\"\n",
    "csv_savepath = \"./data/updated_player_headshots.csv\"\n",
    "\n",
    "# Check if player_headshots.csv file exists and updated_player_headshots.csv file does not exist\n",
    "if os.path.exists(csv_filepath) and not os.path.exists(csv_savepath):\n",
    "    # Open player headshots CSV file\n",
    "    player_url_df = pd.read_csv(csv_filepath)\n",
    "\n",
    "    # Remove period in front of URLs inside circular_player_url column\n",
    "    player_url_df[\"circular_player_url\"] = player_url_df[\"circular_player_url\"].str.replace(r\"\\.\", \"\", n=1, regex=True)\n",
    "\n",
    "    # Replace player URL column with updated circular image URLs\n",
    "    player_url_df[\"player_url\"] = player_url_df[\"circular_player_url\"].apply(\n",
    "        lambda url: f\"https://raw.githubusercontent.com/jung-hyung-lee/nba-global-trends/refs/heads/main/{url}\"\n",
    "    )\n",
    "\n",
    "    # Drop circular_player_url\n",
    "    player_url_df.drop(columns=[\"circular_player_url\"], inplace=True)\n",
    "\n",
    "    # Save updated file\n",
    "    player_url_df.to_csv(csv_savepath, index=False)\n",
    "    print(f\"Updated circular image URLs saved to: {csv_savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merging**\n",
    "\n",
    "The two DataFrames obtained from Basketball-Reference and NBA API will be merged based on `player name`, the `season`, the `team`, and number of `games played`. The resulting merged dataframe will contain all of this information along with `all 8 collected advanced statistics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_diff_df = pd.merge(\n",
    "    bball_ref_cleaned,\n",
    "    nba_cleaned,\n",
    "    on=['player', 'season', 'team', 'games_played'],\n",
    "    how='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evidenced below, any remaining records that do not match on player name, season, team, and number of games played result from inherent inconsistencies that exist between Basketball-Reference and the NBA API and how they had recorded the data. These include different team labels and very similar yet not identical number of games played. Since the number of records is not significant, these records will simply be removed through an inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_df = merged_diff_df[merged_diff_df.isnull().any(axis=1)]\n",
    "print(missing_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(\n",
    "    bball_ref_cleaned,\n",
    "    nba_cleaned,\n",
    "    on=['player', 'season', 'team', 'games_played'],\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.sort_values(by=['player', 'season'])\n",
    "\n",
    "# Save final DataFrame as csv\n",
    "if not os.path.exists(\"./data/final_df.csv\"):\n",
    "    final_df.to_csv(\"./data/final_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Exploratory Data Analysis (EDA)**\n",
    "\n",
    "This section of the project will aim to uncover underlying patterns and correlations that may exist within the data. It will also look at how advanced statistics are distributed and some basic descriptive statistics that can give us a broad outlook on league averages over the last three seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**League-Wide Averages**\n",
    "\n",
    "- `Games Played`: The average player played in roughly 51 games out of 82 games\n",
    "- `PER`: Mean of 13.6 is slightly below the theoretical league-wide average of 15 likely due to low-minute players dragging unweighted average down\n",
    "- `TS%`: Average of 56% aligns well with modern NBA scoring efficiency trends \n",
    "- `USG`: Reflects the percentage of team possessions a player uses. 18.59% is slightly below league average of 20%, which aligns with dataset including bench players\n",
    "- `WS_48`: 0.086 average is close to historical average of 0.1 for typical NBA player\n",
    "- `BPM`: Unweighted mean of -1.12 is indicative that dataset contains many low-minute players\n",
    "- `VORP`: Suggets most players are slightly above replacement-level production\n",
    "- `Offensive Rating`: Indicates 109.66 average points per 100 possessions while on court\n",
    "- `Defensive Rating`: Indicates 111.02 average points allowed per 100 possessions while on court \n",
    "\n",
    "**Variance**\n",
    "\n",
    "Outside of true shooting percentage, all advanced statistics have high standard deviations, meaning the data is more spread out from the mean rather than clustering tightly around it. In basketball analytics, high variance is indicative of player performane varying significantly across the datatset as there are large gaps in production between the best and worst players. Had the standard deviations been low, it would mean most players perform very similarly with few outliers which would not be a truthful representation of the league.\n",
    "\n",
    "**Outliers**\n",
    "\n",
    "Extreme values suggests a mix of limited-minute players and exceptional performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = final_df.select_dtypes([\"object\"]).columns.tolist()\n",
    "# For purposes of EDA, player name and team label columns are not of interest\n",
    "categorical_variables.remove('player')\n",
    "categorical_variables.remove('team')\n",
    "numeric_variables = final_df.select_dtypes(['float64', 'int64']).columns.tolist()\n",
    "print(f\"Categorical Variables: {categorical_variables}\")\n",
    "print(f\"Numeric Variables: {numeric_variables}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Univariate Analysis: Histograms/Bar Charts and Boxplots**\n",
    "\n",
    "To better understand how each column is distributed and identify and outliers that may be present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Histograms of Numeric Variables**\n",
    "\n",
    "- `Games Played`: Left-skewed with majority of players playing more than 55 games but few players playing a very small number of games, pulling mean down.\n",
    "- `PER`: Approximately normal with majority of PER scores centering around 13 or 14. Very slightly positively-skewed.\n",
    "- `TS%`: Approximately normal with majority of players shooting between 55 and 60%.\n",
    "- `USG%`: Right-skewed with head being longer than tail. Most players average between 15-18% but few superstar players with extremely high usage percentage likely pulling mean up.\n",
    "- `WS-48`: Approximately normal with slight positive-skewness.\n",
    "- `BPM`: Approximately normal with slight negative-skewness\n",
    "- `VORP`: Right-skewed with majority of players having 0 VORP but few players with extremely high VORP ratings pulling mean up.\n",
    "- `MIN`: Approximately normal with flat peak, indicating large spread. Indicative of dataset containing all players including bench players to superstars.\n",
    "- `Offensive Rating`: Approximately normal with slight negative-skewness. \n",
    "- `Defensive Rating`: Approximately normal with slight negative-skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Numeric Variables\n",
    "num_bins = int(np.sqrt(len(final_df)))\n",
    "\n",
    "# Define grid size\n",
    "rows = 4\n",
    "cols = 3\n",
    "\n",
    "# Create grid of subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(18, 12))\n",
    "\n",
    "# Flatten 2D axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_variables):\n",
    "    sns.histplot(final_df[col], bins=num_bins, ax=axes[i], edgecolor='black')\n",
    "    axes[i].set_title(f'Histogram of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel(col.capitalize(), fontsize=10)\n",
    "    axes[i].set_ylabel('count', fontsize=10)\n",
    "\n",
    "# Remove empty subplots if any\n",
    "for i in range(len(numeric_variables), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Boxplots of Numeric Variables**\n",
    "\n",
    "- `Games Played`: Thicker box indicates large spread around the median with average 50% of players playing between approximately 38 to 68 games for the season.\n",
    "- `PER`: Thin box indicates PER scores cluster closely around the median which appears to be slightly below 15. There are a significant number of outliers for both positive and negative PER scores, which is indicative of the database encompassing all calibre of players.\n",
    "- `TS%`: Thin box suggests true shooting percentage for players centre closely around the median of roughly 0.57. There appears to be significantly more outliers with extremely low true shooting percentage values, indicating the unweighted mean may have been lowered.\n",
    "- `USG%`: Relatively thick box with 50% of players receiving 15% to 21% of team plays with median value being approximately 17%. There is a significantly greater number of outliers comprised of extremely high usage players, which reflects the large number of superstars that exist within the NBA.\n",
    "- `WS-48`: Noticeably thin box with median value of approximately 0.1, indicating the average player would likely perform very close to the median value. However, there are significantly more negative outliers than positive ones, likely resulting in the mean being pulled down.\n",
    "- `BPM`: Noticeably thin box with median value slightly below 0. While there is a large number of both positive and negative outliers, there seems to be slightly more negative outliers and the negative outliers seem to be more significant in value. \n",
    "- `VORP`: Relatively thick box with median hovering slightly above 0 at approximately 0.1. The median is much closer to the 1st quartile than the 3rd quartile indicating there are significantly larger gaps in VORP values between an average player and major contributor (e.g. starter) and an average player and minor contributor (e.g. bench player). This is further reinforced by the significant number of positive outliers (e.g. star players).\n",
    "- `MIN`: Noticeably thick box with median of 20 minutes played per game, suggesting high variance in minutes played among players. Expectedly, no outliers are present.\n",
    "- `Offensive Rating` and `Defensive Rating`: Both extremely thin boxes with median values of approximately 110 points per 100 possessions. There are significantly more negative outliers present in both statistics, indicating unweighted mean may have been pulled down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define figure size\n",
    "rows = 4\n",
    "cols = 3\n",
    "\n",
    "# Create grid of subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 16))\n",
    "\n",
    "# Flatten 2D axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_variables):\n",
    "    sns.boxplot(y=final_df[col], ax=axes[i], color='skyblue')\n",
    "    axes[i].set_title(f\"Boxplot of {col}\", fontsize=12, fontweight='bold')\n",
    "    axes[i].set_ylabel(col.capitalize(), fontsize=10)\n",
    "\n",
    "for i in range(len(numeric_variables), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Bar Charts for Categorical Variables**\n",
    "\n",
    "Since the dataset includes a large number of nationalities, only the **top 10 most common** have been selected for visualisation. The distribution clearly highlights a significant dominance of **American players**, who make up approximately **76.7%** of the dataset. In contrast, the second most common nationality, **Canadian players**, account for only **4.2%**, revealing a stark discrepancy between the two groups.  \n",
    "\n",
    "One possible explanation for this gap is that many **foreign players may have only played for a single season** before moving to different leagues. As a result, their records would have been removed from the dataset, contributing to the imbalance observed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain 10 most common nationalities\n",
    "top_n = 10\n",
    "top_nationalities = final_df['nationality'].value_counts().nlargest(top_n)\n",
    "\n",
    "# Calculate percentages\n",
    "total_count = final_df['nationality'].count()\n",
    "top_nationalities_percentage = (top_nationalities / total_count) * 100\n",
    "\n",
    "# Define figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(\n",
    "    x=top_nationalities.index,\n",
    "    y=top_nationalities.values,\n",
    "    palette='pastel',\n",
    "    edgecolor='black',\n",
    "    hue=top_nationalities.index,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Annotate bars with percentage values\n",
    "for i, value in enumerate(top_nationalities.values):\n",
    "    percentage = top_nationalities_percentage.iloc[i]\n",
    "    ax.text(i, value + 10, f\"{percentage:.1f}%\", ha='center', fontsize=10)\n",
    "\n",
    "plt.title(\"Top 10 Most Common Nationalities in Dataset\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Nationality', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of data across seasons is relatively even, with the 2022-23 season having the highest number of records at approximately 510, while the 2021-22 season has the lowest at around 440.\n",
    "\n",
    "This fluctuation in player count across seasons is expected, as NBA teams do not have a fixed roster size. Each team can have up to 15 standard contract players, with the option to sign two additional two-way players, bringing the maximum roster size to 17 players.\n",
    "\n",
    "Since the dataset includes players who have participated in at least two seasons, one possible reason for the higher count in 2022-23 is the presence of players who played in both 2021-22 and 2022-23, as well as those who appeared in 2022-23 and 2023-24, but not necessarily all three seasons. This overlapping effect may have resulted in a higher number of unique player records in the middle season (2022-23) compared to the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure seasons are sorted correctly\n",
    "season_order = [\"2021-22\", \"2022-23\", \"2023-24\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=final_df, x='season', order=season_order, hue='season', legend=False, palette='pastel', edgecolor='black')\n",
    "\n",
    "plt.title(\"Count Plot of Past 3 NBA Seasons\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Season\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Multivariate Analysis: Heatmap of Correlation Coefficients**  \n",
    "\n",
    "To examine the relationships between numerical variables in the dataset, we use a **heatmap of correlation coefficients**. This visualisation helps identify the strength and direction of associations between different features. By analysing the correlation matrix, we can detect potential linear relationships, multicollinearity, or patterns that may inform further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DataFrame with only numeric columns\n",
    "numeric_df = final_df.select_dtypes(['number'])\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_mat = numeric_df.corr()\n",
    "\n",
    "# Define figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "    corr_mat,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    linewidths=0.5,\n",
    "    cbar=True\n",
    ")\n",
    "\n",
    "plt.title(\"Heatmap of Correlation Coefficients\", fontsize=14, fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis of Heatmap**\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "- **Strong Positive Correlations:**  \n",
    "  The strong correlations between Box Plus-Minus (BPM), Win Shares per 48 Minutes (WS/48), and Player Efficiency Rating (PER) suggest that players with higher efficiency ratings tend to contribute more positively to team success.  \n",
    "  - `BPM` and `PER` (**0.89**)  \n",
    "  - `WS/48` and `BPM` (**0.87**)  \n",
    "  - `WS/48` and `PER` (**0.86**)  \n",
    "  These relationships are expected since BPM and WS/48 reflect **overall impact**, while PER measures **individual per-minute efficiency**, both of which typically align in high-performing players.\n",
    "\n",
    "- **Moderate Correlations:**  \n",
    "  - `Minutes Played per Game (MIN)` shares a moderate positive correlation with Total Games Played (games_played) (0.63) and Value Over Replacement Player (VORP) (0.59).  \n",
    "  - This suggests that players logging more minutes per game are also more likely to play a higher total number of games across the season and accumulate a higher VORP, a cumulative impact stat.  \n",
    "  - The positive correlation between VORP and minutes played aligns with expectations, as higher total playing time naturally leads to greater cumulative contributions\n",
    "\n",
    "- **Weak or No Correlation:**  \n",
    "  - `Defensive Rating (def_rating)` shows little to no correlation with most other advanced metrics.  \n",
    "  - Interestingly, `def_rating` even has a slight negative correlation with `BPM` (0.05) suggesting that defensive contributions may not be well captured in other impact metrics.  \n",
    "  - This raises concerns that offensive performance may be weighted more heavily than defense in standard advanced stats.\n",
    "\n",
    "### **Key Takeaways & Next Steps:**\n",
    "âœ”ï¸ The heatmap indicates that **most advanced statistics are positively correlated with one another, except for Defensive Rating**.  \n",
    "âœ”ï¸ This suggests that **offensive statistics may carry more weight** than defensive ones in their computation.  \n",
    "âœ”ï¸ **To improve balance in player evaluation**:\n",
    "  - **Rebalance the weights in the composite score** to **increase the impact of defensive rating**, ensuring that defensive performance is properly rewarded in the final ranking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Storing, Filtering, and Retrieving Data**\n",
    "\n",
    "**Connect** to a PostgreSQL database, **create tables** to store cleaned data, and **execute queries** with filters to retrieve and store data in DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PostgreSQL-Related Functions**\n",
    "\n",
    "Define `environment variables` and `functions` necessary to store, filter, and retrieve data from a PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read environment variables\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "\n",
    "def connect_db():\n",
    "    \"\"\"Establishes a connection to the PostgreSQL databse\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT\n",
    "        )\n",
    "        print(\"Connection to the database was successful.\")\n",
    "        return conn\n",
    "    except OperationalError as e:\n",
    "        print(f\"Error: Failed to connect to the PostgreSQL database.\\nDetails:{e}\")\n",
    "        return None\n",
    "\n",
    "def table_exists(cursor, table_name):\n",
    "    \"\"\"Checks if a table exists in the PostgreSQL database\"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT EXISTS(\n",
    "        SELECT FROM information_schema.tables\n",
    "        WHERE table_name = %s\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (table_name,))\n",
    "    return cursor.fetchone()[0]\n",
    "\n",
    "\n",
    "def check_and_create_table(cursor, conn):\n",
    "    \"\"\"Checks if the required tables exist and creates them if not\"\"\"\n",
    "    tables = {\n",
    "        \"all_three_seasons\": \"\"\"\n",
    "            CREATE TABLE all_three_seasons (\n",
    "                player VARCHAR(50) NOT NULL,\n",
    "                team VARCHAR(10) NOT NULL,\n",
    "                games_played INT NOT NULL,\n",
    "                per FLOAT NOT NULL,\n",
    "                ts FLOAT NOT NULL,\n",
    "                usg FLOAT NOT NULL,\n",
    "                ws_48 FLOAT NOT NULL,\n",
    "                bpm FLOAT NOT NULL,\n",
    "                vorp FLOAT NOT NULL,\n",
    "                season VARCHAR(10) NOT NULL,\n",
    "                min FLOAT NOT NULL,\n",
    "                off_rating FLOAT NOT NULL,\n",
    "                def_rating FLOAT NOT NULL\n",
    "            );\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    for table, create_query in tables.items():\n",
    "        if not table_exists(cursor, table):\n",
    "            cursor.execute(create_query)\n",
    "            conn.commit()\n",
    "            print(f\" Table `{table}` created.\")\n",
    "\n",
    "def load_data(engine):\n",
    "    \"\"\"Loads data from CSV files into PostgreSQL database\"\"\"\n",
    "    datasets = {\n",
    "        \"all_three_seasons\": \"./data/final_df.csv\"\n",
    "    }\n",
    "    try:\n",
    "        for table, csv_path in datasets.items():\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df.to_sql(table, engine, if_exists=\"replace\", index=False)\n",
    "            print(f\"Data loaded into `{table}`\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load data into `{table}`: {e}\")\n",
    "    \n",
    "def retrieve_data(engine, query, var_name=\"DataFrame\"):\n",
    "    \"\"\"Executes the given SQL query\"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            df = pd.read_sql(query, conn)\n",
    "            print(f\"Successfully retrieved data and stored in '{var_name}'\")\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Main Execution**\n",
    "\n",
    "Leverages the PostgreSQL-related functions to connect to a PSQL database named `nba_players`, creates tables when necessary inside the database, stores csv data within these newly created tables, executes queries to retrieve data user wants, and finally saves the retrieved data as new DataFrames.\n",
    "\n",
    "The `weighted_query` below obtains the weighted averages of all advanced statistics based on total minutes played **for players that played at least**:\n",
    "- **15 minutes per game** (one game lasts 48 minutes)\n",
    "- **41 games played** (one full season is 82 games)\n",
    "- **2 out of 3 seasons**\n",
    "\n",
    " These weighted-averages will be used when computing a composite score to measure the performance of each player across the past 3 seasons to ultimately rank players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "conn = connect_db()\n",
    "\n",
    "# Define query to obtain weighted averages of all advanced statistics based on total minutes played per season\n",
    "weighted_query = \"\"\"\n",
    "    WITH total_minutes_cte AS(\n",
    "        SELECT\n",
    "            *,\n",
    "            (min * games_played) AS total_minutes\n",
    "        FROM all_three_seasons\n",
    "        WHERE                  -- Filter for players that played at least 15 minutes per game and 41 out of 82 games per season\n",
    "            min >= 15 AND\n",
    "            games_played >= 41\n",
    "    )\n",
    "    SELECT\n",
    "        player,\n",
    "        nationality,\n",
    "        CASE\n",
    "            WHEN nationality = 'USA' THEN 'USA'\n",
    "            ELSE 'International'\n",
    "        END AS player_origin,\n",
    "        SUM(total_minutes * per) / SUM(total_minutes) AS avg_per,       \n",
    "        SUM(total_minutes * ts) / SUM(total_minutes) AS avg_ts,       \n",
    "        SUM(total_minutes * usg) / SUM(total_minutes) AS avg_usg,\n",
    "        SUM(total_minutes * ws_48) / SUM(total_minutes) AS avg_ws_48,\n",
    "        SUM(total_minutes * bpm) / SUM(total_minutes) AS avg_bpm,\n",
    "        SUM(total_minutes * vorp) / SUM(total_minutes) AS avg_vorp,\n",
    "        SUM(total_minutes * off_rating) / SUM(total_minutes) AS avg_off_rating,\n",
    "        SUM(total_minutes * def_rating) / SUM(total_minutes) AS avg_def_rating\n",
    "    FROM total_minutes_cte\n",
    "    WHERE total_minutes > 0\n",
    "    GROUP BY player, nationality, player_origin\n",
    "    HAVING COUNT(DISTINCT season) >= 2\n",
    "    ORDER BY player\n",
    "    ;\n",
    "\"\"\"\n",
    "\n",
    "main_query = \"\"\"\n",
    "    WITH player_season_counts AS (\n",
    "        SELECT \n",
    "            player, \n",
    "            COUNT(DISTINCT season) AS seasons_played\n",
    "        FROM all_three_seasons\n",
    "        WHERE min >= 15 \n",
    "        AND games_played >= 41\n",
    "        GROUP BY player\n",
    "    )\n",
    "    SELECT \n",
    "        a.*,\n",
    "        CASE \n",
    "            WHEN a.nationality = 'USA' THEN 'USA' \n",
    "            ELSE 'International' \n",
    "        END AS player_origin,\n",
    "        psc.seasons_played\n",
    "    FROM all_three_seasons a\n",
    "    JOIN player_season_counts psc \n",
    "        ON a.player = psc.player\n",
    "    WHERE psc.seasons_played >= 2;\n",
    "\"\"\"\n",
    "\n",
    "if conn is None:\n",
    "    print(\"Connection failed. Exiting...\")\n",
    "    sys.exit\n",
    "\n",
    "try:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check and create tables if they do not exist\n",
    "    check_and_create_table(cursor, conn)\n",
    "\n",
    "    # Close psycopg2 connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    # SQLAlchemy connection for efficient data operations\n",
    "    engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "\n",
    "    # Load data into tables\n",
    "    load_data(engine)\n",
    "\n",
    "    # Execute query and store results in DataFrame\n",
    "    weighted_avg_df = retrieve_data(engine, weighted_query, var_name=\"weighted_average_df\")\n",
    "    main_df = retrieve_data(engine, main_query, var_name=\"main_df\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "\n",
    "finally:\n",
    "    print(\"Script execution completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Ranking Players**\n",
    "\n",
    "Compute the `composite score` for each player based on **normalised weighted-averages** of advanced statistics to **rank players** that played at least 2 out of the last 3 NBA seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalisation**\n",
    "\n",
    "Before calculating the composite score, the weighted-averages must be normalised in order to **prevent large statistics such as PER and BPM from dominating the score**. In other words, normalising the averages ensures fair contribution from all statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise advanced statistics\n",
    "scaler = MinMaxScaler()\n",
    "metrics = ['per', 'ts', 'usg', 'ws_48', 'bpm', 'vorp', 'off_rating', 'def_rating']\n",
    "# Create copy to normalise advanced statistics\n",
    "normalised_main_df = main_df.copy()\n",
    "normalised_main_df[metrics] = scaler.fit_transform(main_df[metrics])\n",
    "\n",
    "# Normalise weighted-averages of all advanced statistics\n",
    "scaler = MinMaxScaler()\n",
    "avg_metrics = ['avg_per', 'avg_ts', 'avg_usg', 'avg_ws_48', 'avg_bpm', 'avg_vorp', 'avg_off_rating', 'avg_def_rating']\n",
    "# Create copy to normalise weighted advanced statistics\n",
    "normalised_avg_df = weighted_avg_df.copy()\n",
    "normalised_avg_df[avg_metrics] = scaler.fit_transform(weighted_avg_df[avg_metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Composite Score**\n",
    "\n",
    "The **composite score** is constructed by first **normalising** the advanced statistic to ensure consistency across different metrics.  \n",
    "\n",
    "The **correlation heatmap** reveals that **defensive rating** has little to no correlation with the other seven statistics, which primarily reward offensive contributions. This highlights a key imbalance, as **modern NBA metrics tend to favour offence-focused players.**  \n",
    "\n",
    "To address this, the composite score is **weighted 70% towards offensive impact** (distributed across the seven offence-oriented metrics) and **30% towards defensive rating**. This **70:30 split** ensures that **defensive effectiveness receives meaningful consideration**, while still reflecting the leagueâ€™s offensive emphasis. This approach accounts for **both ends of the court** without disproportionately favouring one over the other.\n",
    "\n",
    "| **Advanced Statistic**         | **Weight (%)** | **Rationale** |\n",
    "|---------------------------|------------|--------------------------------------------------------------------------|\n",
    "| Defensive Rating      | 30%        | Balances offensive bias by ensuring defensive impact is strongly considered |\n",
    "| PER                  | 8%         | Measures overall impact but highly correlated with BPM and WS/48, requiring reduced weight |\n",
    "| BPM                  | 8%         | Accounts for box score impact but overlaps significantly with PER and WS/48 |\n",
    "| VORP                 | 8%         | Captures overall value over replacement level but correlates with PER and BPM |\n",
    "| True Shooting % (TS%) | 11.5%      | Reflects scoring efficiency, an independent metric not tied to counting stats |\n",
    "| Usage % (USG%)       | 11.5%      | Shows offensive role and involvement, providing unique insight |\n",
    "| Win Shares per 48 (WS/48) | 11.5%  | Rewards consistent contributions but is highly tied to PER and BPM |\n",
    "| Offensive Rating      | 11.5%      | Measures offensive efficiency directly, adding a distinct dimension |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for each metric\n",
    "weights = [0.08, 0.115, 0.115, 0.115, 0.08, 0.08, 0.115, 0.3]\n",
    "main_metric_weight = dict(zip(metrics, weights))\n",
    "weighted_metric_weight = dict(zip(avg_metrics, weights))\n",
    "\n",
    "# Calculate composite score for all advanced statistics\n",
    "main_df[\"composite_score\"] = normalised_main_df[\n",
    "    list(main_metric_weight.keys())\n",
    "].mul(main_metric_weight).sum(axis=1)\n",
    "\n",
    "# Calculate composite score for all weighted statistics\n",
    "weighted_avg_df[\"composite_score\"] = normalised_avg_df[\n",
    "    list(weighted_metric_weight.keys())\n",
    "].mul(weighted_metric_weight).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ranking of all players for each season based on composite score\n",
    "main_df['rank'] = main_df.groupby(['season'])['composite_score'].rank(method='first', ascending=False)\n",
    "main_df['rank'] = main_df['rank'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the data as csv files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data/main_df.csv'):\n",
    "    main_df.to_csv(\"./data/main_df.csv\", index=False)\n",
    "if not os.path.exists('./data/weighted_df.csv'):\n",
    "    weighted_avg_df.to_csv(\"./data/weighted_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[main_df['player'].str.contains('Giannis')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Top 10 Players Over Last 3 NBA Seasons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg_df[['player', 'nationality', 'composite_score']].nlargest(10, 'composite_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nba_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
